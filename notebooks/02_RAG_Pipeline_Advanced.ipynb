{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrOgCpN0p1Ha"
      },
      "outputs": [],
      "source": [
        "# Libraries install ho rahi hain\n",
        "!pip install -q langchain langchain-community chromadb sentence-transformers pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4SXZuBqqOjS",
        "outputId": "e907f279-22be-4eb5-aec7-883623e575df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Pages: 7\n",
            "Pehle page ka sample: V erifyNo w — A Quick \n",
            "Onboar ding Guide\n",
            " St ep 1: Sign Up & Log In \n",
            "Go t o Message C entral Signupu.lS\n",
            "Cre a t e y our f ree accountu.lS\n",
            "Y ou’ll inst antly get f ree credits t o t est O TP s\n",
            "  Tip: U\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# PDF ko read karna\n",
        "loader = PyPDFLoader(\"test.pdf\")\n",
        "data = loader.load()\n",
        "\n",
        "print(f\"Total Pages: {len(data)}\")\n",
        "print(f\"Pehle page ka sample: {data[0].page_content[:200]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjj4GwP4qop5",
        "outputId": "44b41b93-0521-4d91-9e99-b434290e7dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.6)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.12.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l5nEII5qdj-",
        "outputId": "3012a753-b669-4990-c848-898a12ae0dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Chunks: 11\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 1000 characters ka ek chunk, aur 200 characters overlap\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = text_splitter.split_documents(data)\n",
        "\n",
        "print(f\"Total Chunks: {len(chunks)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1adIwzrrw6O",
        "outputId": "e52d4c99-d461-47e8-9134-c1180fc73058"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3061317497.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector Database taiyaar hai!\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Embedding model download hoga (Free & Open Source)\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Vector Database banana\n",
        "vector_db = Chroma.from_documents(documents=chunks, embedding=embedding_model)\n",
        "\n",
        "print(\"Vector Database taiyaar hai!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXskvCJfrz40",
        "outputId": "8cdac05a-7a2b-4916-c9bc-b68b17d46ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Chunk 1:\n",
            " V erifyNo w — A Quick \n",
            "Onboar ding Guide\n",
            "04\n",
            "Send O TP\n",
            "T o sendOtp  on a mobile number belo w are the request paramet ers. The authen tic a tion t ok en is \n",
            "required t o send O TP which is genera t ed b y the genera t ed t ok en API (which y ou c an .etind abo v e in \n",
            "Introduction section).\n",
            "  API P aramet er T ype Manda t ory?\n",
            "authT ok en String Y es\n",
            "R equest URL P a th:\n",
            "A successful response will return a 200 st a tus code.\n",
            "POST\n",
            "/verification/ /send v3\n",
            "R equest URL P aramet ers:\n",
            "Field T ype Manda t ory? Descrip tion\n",
            "cust omerId String y es C ountry code \n",
            "o tpLength Int eger no Send a number \n",
            "betw een 4 and 8. \n",
            "Def ault is 4\n",
            "mobileNumber String y es Mobile number \n",
            "f or single t e xt\n",
            ".endao wT ype String y es W e send O TP \n",
            "using multiple \n",
            "mediums lik e \n",
            "SMS ,  W ha tsApp ,  \n",
            "email ,  et c.  F or \n",
            "no w ,  use SMS \n",
            "only\n",
            "\n",
            "Chunk 2:\n",
            " &scope=NEW&country=91&email=test%40messagecentral.com' rh?/\n",
            "--header 'accept: */*'\n",
            "https://cpaas.messagecentral.com/auth/v1/\n",
            "authentication/token?\n",
            " NO TE:  T o con v ert a cURL command int o code using P ostman, open P ostman, import the cURL \n",
            "command via the \"Import\" butt on, and then genera t e the code in y our pref erred la nguage b y \n",
            "clicking the \"C ode\" butt on on the right side o f the request.\n",
            "02\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the main topic of this document?\" # Apne PDF ke hisaab se pucho\n",
        "docs = vector_db.similarity_search(query, k=2)\n",
        "\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"\\nChunk {i+1}:\\n\", doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fv9O-SSsZ8F",
        "outputId": "ced716b2-dbe3-4a54-bb1d-f7b346866da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w-80jP8sz-w",
        "outputId": "5b23309e-582e-41ad-8834-7964cbfb1b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_classic in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.5 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (1.2.6)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (1.1.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (0.4.59)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (6.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (2.32.5)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (2.0.45)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain_classic) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain_classic) (25.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain_classic) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain_classic) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain_classic) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_classic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_classic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_classic) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain_classic) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain_classic) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain_classic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain_classic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain_classic) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain_classic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc7J1fn2sZCe",
        "outputId": "2a03709f-a82f-4695-911a-035f801f1b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- AI ANSWER ---\n",
            "The main points of this document are:\n",
            "\n",
            "1. **Sign Up and Log In**: Create a free account on Message Central Signup to get free credits for testing OTPs.\n",
            "2. **API Integration**: Integrate the VerifyNow API into your application using ready-made code snippets or a video tutorial.\n",
            "3. **API Parameters**: Understand the required API parameters, such as `u`, `type`, and `authToken`.\n",
            "4. **Validate OTP**: Use the `validateOtp` method to validate a one-time password (OTP) for customers.\n",
            "5. **Authentication**: Obtain an authentication token by calling the `/auth/v1/authentication/token` endpoint with required parameters such as `customerId`, `key`, and `scope`.\n",
            "6. **API Endpoints**: Use the provided API endpoints, such as `/verification/validateOtp/v3`, to interact with the VerifyNow API.\n",
            "7. **cURL Examples**: Use cURL commands to test API requests, such as validating an OTP or obtaining an authentication token.\n",
            "\n",
            "These points provide a general overview of how to get started with the VerifyNow API and how to use its various endpoints to validate OTPs and authenticate users.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_classic.chains import create_retrieval_chain\n",
        "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# A. API Key Setup\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "\n",
        "# B. LLM Initialize (Groq is super fast!)\n",
        "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0)\n",
        "\n",
        "# C. Professional Prompt Template (Workshop mein ye dikhana imp hai)\n",
        "system_prompt = (\n",
        "    \"You are an expert assistant. Use the provided context to answer the user's question. \"\n",
        "    \"If the answer isn't in the context, just say you don't know. \"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# D. The Chain Building (Modern LCEL Way)\n",
        "# Pehle 'Documents' ko 'Prompt' ke saath jodne wali chain\n",
        "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Phir 'Retriever' aur 'Documents Chain' ko milakar final RAG chain\n",
        "rag_chain = create_retrieval_chain(vector_db.as_retriever(), combine_docs_chain)\n",
        "\n",
        "# E. Execution\n",
        "response = rag_chain.invoke({\"input\": \"What are the main points of this document?\"})\n",
        "\n",
        "print(\"--- AI ANSWER ---\")\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUqHvkABt-5c",
        "outputId": "4d7d8848-2356-4ba2-ba85-14754ba5d908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Chunk 1 (Source: 0) ---\n",
            "V erifyNo w — A Quick \n",
            "Onboar ding Guide\n",
            " St ep 1: Sign Up & Log In \n",
            "Go t o Message C entral Signupu.lS\n",
            "Cre a t e y our f ree accountu.lS\n",
            "Y ou’ll inst antly get f ree credits t o t est O TP s\n",
            "  Tip: U...\n",
            "\n",
            "--- Chunk 2 (Source: 5) ---\n",
            "V erifyNo w — A Quick \n",
            "Onboar ding Guide\n",
            "05\n",
            "V alida t e O TP\n",
            "The  v alida t eOtp method is a REST API endpoint f or v alida ting a one-time pass w ord ( O TP) f or \n",
            "cust omers.\n",
            "R equest He ader T ype ...\n",
            "\n",
            "--- Chunk 3 (Source: 6) ---\n",
            "V erifyNo w — A Quick \n",
            "Onboar ding Guide\n",
            "06\n",
            "cURL\n",
            "kJ66\n",
            "kJ61\n",
            "kJ6x\n",
            "kJ6j\n",
            "5\n",
            "curl --loc a tion 'https://\n",
            "&v erikJ4=c a tionId=29 49&code=147 6' kJWE\n",
            "--he ader 'authT ok en: \n",
            "eyJhbGciOiJIUzUxMiJ9 .eyJzdWIiOi...\n",
            "\n",
            "--- Chunk 4 (Source: 1) ---\n",
            "V erifyNo w — A Quick \n",
            "Onboar ding Guide\n",
            "This API returns a t ok en tha t must be included in all subsequent c alls. The authenti c a tion t ok en is \n",
            "required t o v alida t e the user and must be inc...\n"
          ]
        }
      ],
      "source": [
        "# Ye dikhayega ki database se kaunse chunks uthaye gaye\n",
        "for i, doc in enumerate(response[\"context\"]):\n",
        "    print(f\"\\n--- Chunk {i+1} (Source: {doc.metadata.get('page', 'N/A')}) ---\")\n",
        "    print(doc.page_content[:200] + \"...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
